{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3d91ANQ1Eud+IFG+En0Tr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanish777/SNLP/blob/main/Automatic_report_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkIg7zgWscII",
        "outputId": "10696a98-0839-4a37-8f16-ad2ca0a93bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: weasyprint in /usr/local/lib/python3.10/dist-packages (62.3)\n",
            "Requirement already satisfied: pydyf>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (0.11.0)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (1.16.0)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (1.1)\n",
            "Requirement already satisfied: tinycss2>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (1.3.0)\n",
            "Requirement already satisfied: cssselect2>=0.1 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (0.7.0)\n",
            "Requirement already satisfied: Pyphen>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (0.15.0)\n",
            "Requirement already satisfied: Pillow>=9.1.0 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (9.4.0)\n",
            "Requirement already satisfied: fonttools>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (4.53.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=0.6->weasyprint) (2.22)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2>=0.1->weasyprint) (0.5.1)\n",
            "Requirement already satisfied: zopfli>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (0.2.3)\n",
            "Requirement already satisfied: brotli>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->weasyprint) (1.16.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2) (2.1.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "!pip install weasyprint\n",
        "!pip install jinja2\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from jinja2 import Template\n",
        "import weasyprint\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create sample data\n",
        "data = {\n",
        "    'id': [1, 2, 3, 4, 5],\n",
        "    'text': [\n",
        "        \"Apple is looking at buying U.K. startup for $1 billion. The company is based in London.\",\n",
        "        \"Google has announced a new AI-based search feature. It aims to improve search accuracy.\",\n",
        "        \"Microsoft is investing heavily in cloud computing. Their Azure platform is growing rapidly.\",\n",
        "        \"Amazon continues to expand its logistics network. They are opening new warehouses worldwide.\",\n",
        "        \"Facebook is working on new privacy features. They aim to protect user data more effectively.\"\n",
        "    ]\n",
        "}\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('sample_text.csv', index=False)\n",
        "\n",
        "# Download the CSV file (uncomment if running in a notebook or local environment)\n",
        "# from google.colab import files\n",
        "# files.download('sample_text.csv')"
      ],
      "metadata": {
        "id": "lGb-3MsM9zg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Module 1: Data Extraction\n",
        "def fetch_data(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raises HTTPError for bad responses\n",
        "        return response.text\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data from {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example URL with a publicly accessible HTML table\n",
        "url = 'https://www.w3schools.com/html/html_tables.asp'\n",
        "html_content = fetch_data(url)\n",
        "\n",
        "if html_content:\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    table = soup.find('table')\n",
        "    if table:\n",
        "        data = []\n",
        "        for row in table.find_all('tr'):\n",
        "            cols = row.find_all(['td', 'th'])\n",
        "            cols = [ele.text.strip() for ele in cols]\n",
        "            if cols:  # Only append if cols is not empty\n",
        "                data.append(cols)\n",
        "\n",
        "        # Determine the maximum number of columns in the data\n",
        "        max_cols = max(len(row) for row in data)\n",
        "\n",
        "        # Fill rows with missing columns with None\n",
        "        for row in data:\n",
        "            while len(row) < max_cols:\n",
        "                row.append(None)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame(data[1:], columns=data[0])\n",
        "        print(\"Data Extraction Output:\")\n",
        "        print(df.head())\n",
        "    else:\n",
        "        print(\"No table found in the HTML content.\")\n",
        "else:\n",
        "        print(\"Failed to retrieve data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnfkN22xsi4a",
        "outputId": "025e4249-333b-46de-9be2-d95a460b9021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Extraction Output:\n",
            "                        Company          Contact  Country\n",
            "0           Alfreds Futterkiste     Maria Anders  Germany\n",
            "1    Centro comercial Moctezuma  Francisco Chang   Mexico\n",
            "2                  Ernst Handel    Roland Mendel  Austria\n",
            "3                Island Trading    Helen Bennett       UK\n",
            "4  Laughing Bacchus Winecellars  Yoshi Tannamuri   Canada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#module 2: text processing and analysis\n",
        "# Define text analysis functions\n",
        "def analyze_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [w for w in tokens if w.lower() not in stop_words]\n",
        "    fdist = FreqDist(filtered_tokens)\n",
        "    return fdist.most_common(10)  # Return top 10 most common words\n",
        "\n",
        "def summarize_text(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    return '\\n'.join(sentences)  # Taking all sentences as summary\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = '/content/sample_text.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Concatenate all text data\n",
        "all_text = ' '.join(df['text'])\n",
        "\n",
        "# Analyze and summarize the text\n",
        "common_words = analyze_text(all_text)\n",
        "summary = summarize_text(all_text)\n",
        "\n",
        "# Print the results\n",
        "print(\"\\nText Analysis Output:\")\n",
        "print(\"Common Words:\", common_words)\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asb27QEL7UoP",
        "outputId": "aafddeeb-b4fd-44a1-b941-74b408c8fcf2"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text Analysis Output:\n",
            "Common Words: [('.', 10), ('new', 3), ('search', 2), ('Apple', 1), ('looking', 1), ('buying', 1), ('U.K.', 1), ('startup', 1), ('$', 1), ('1', 1)]\n",
            "Summary: Apple is looking at buying U.K. startup for $1 billion.\n",
            "The company is based in London.\n",
            "Google has announced a new AI-based search feature.\n",
            "It aims to improve search accuracy.\n",
            "Microsoft is investing heavily in cloud computing.\n",
            "Their Azure platform is growing rapidly.\n",
            "Amazon continues to expand its logistics network.\n",
            "They are opening new warehouses worldwide.\n",
            "Facebook is working on new privacy features.\n",
            "They aim to protect user data more effectively.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Module 3: Report Generation and Formatting\n",
        "def generate_report(summary, common_words):\n",
        "    template = Template('''\n",
        "    <html>\n",
        "    <head><title>Report</title></head>\n",
        "    <body>\n",
        "        <h1>Automatic Report</h1>\n",
        "        <h2>Summary</h2>\n",
        "        <p>{{ summary }}</p>\n",
        "        <h2>Common Words</h2>\n",
        "        <ul>\n",
        "            {% for word, frequency in common_words %}\n",
        "            <li>{{ word }}: {{ frequency }}</li>\n",
        "            {% endfor %}\n",
        "        </ul>\n",
        "    </body>\n",
        "    </html>\n",
        "    ''')\n",
        "\n",
        "    html_content = template.render(summary=summary, common_words=common_words)\n",
        "\n",
        "    # Generate PDF using weasyprint\n",
        "    weasyprint.HTML(string=html_content).write_pdf(\"report.pdf\")\n",
        "    print(\"Report generated as 'report.pdf'\")\n",
        "\n",
        "generate_report(summary, common_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znuu6xZXut76",
        "outputId": "dd7d47bd-2a99-475c-f7e4-f25c7dccc52f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report generated as 'report.pdf'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Module 1: Data Extraction\n",
        "url = 'https://www.w3schools.com/html/html_tables.asp'\n",
        "html_content = fetch_data(url)\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "table = soup.find('table')\n",
        "data = []\n",
        "for row in table.find_all('tr'):\n",
        "    cols = row.find_all('td')\n",
        "    cols = [ele.text.strip() for ele in cols]\n",
        "    data.append(cols)\n",
        "df = pd.DataFrame(data, columns=['Column1', 'Column2', 'Column3'])\n",
        "\n",
        "# Module 2: Text Analysis and Summarization\n",
        "sample_text = \"Apple is looking at buying U.K. startup for $1 billion. The company is based in London.\"\n",
        "common_words = analyze_text(sample_text)\n",
        "summary = summarize_text(sample_text)\n",
        "\n",
        "# Module 3: Report Generation and Formatting\n",
        "generate_report(summary, common_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTUHuN3-1iR0",
        "outputId": "6c7e54ec-f42d-407b-9201-0e85f78354c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report generated as 'report.pdf'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HCMZWwrf9yj3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}